{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-engineer",
   "metadata": {},
   "source": [
    "PatchCamelyon is an immage classification datasets which consists of 327.680 96x96px coloured images. Images come from scans of lymph node sections having or not metastatic tissue. Each image is also paired with a label indicating the presence of such tissue or not. It is already split in training, validation and test sets respectively of 262.144, 32.768, 32.768 samples. All the splits are homogeneously composed by positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading dataset from tensorflow_datasets\n",
    "camelyon = tfds.load('patch_camelyon', as_supervised=True, shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image tensor values will be in range 0-1\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = camelyon['train'].shuffle(1000).batch(32).map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val = camelyon['validation'].batch(32).map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = camelyon['test'].batch(32).map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's build the model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the first and second stage layers.\n",
    "def stage_1_and_2(x):\n",
    "  x = layers.Conv2D(64, (7, 7), strides=2, padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  x = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\")(x)\n",
    "  \n",
    "  x = layers.Conv2D(64, (1, 1), strides=1, padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    " \n",
    "  x = layers.Conv2D(192, (3, 3), strides=1, padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  x = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\")(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the inception layers to be put in stages 3, 4 and 5.\n",
    "\n",
    "def inception_st3(x, filter_sizes, reduction_sizes):\n",
    "  \n",
    "  first_branch = layers.Conv2D(filter_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  second_branch_red = layers.Conv2D(reduction_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  second_branch = layers.Conv2D(filter_sizes[1], (3, 3), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(second_branch_red)\n",
    "  \n",
    "  third_branch_red = layers.Conv2D(reduction_sizes[1], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (3, 3), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch_red)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (3, 3), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch)\n",
    "  \n",
    "  fourth_branch = layers.MaxPool2D(pool_size=(3, 3), strides=1, padding=\"SAME\")(x)\n",
    "  \n",
    "  fourth_branch = layers.Conv2D(filter_sizes[3], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(fourth_branch)\n",
    "  \n",
    "  return layers.concatenate([first_branch, second_branch, third_branch, fourth_branch], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_st4(x, filter_sizes, reduction_sizes):\n",
    "  first_branch = layers.Conv2D(filter_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  second_branch_red = layers.Conv2D(reduction_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  second_branch = layers.Conv2D(filter_sizes[1], (1, 7), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(second_branch_red)\n",
    "  \n",
    "  second_branch = layers.Conv2D(filter_sizes[1], (7, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(second_branch)                  \n",
    "  \n",
    "  third_branch_red = layers.Conv2D(reduction_sizes[1], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (1, 7), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch_red)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (7, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (1, 7), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (7, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch)\n",
    "  \n",
    "  fourth_branch = layers.MaxPool2D(pool_size=(3, 3), strides=1, padding=\"SAME\")(x)\n",
    "  \n",
    "  fourth_branch = layers.Conv2D(filter_sizes[3], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(fourth_branch)\n",
    "  \n",
    "  return layers.concatenate([first_branch, second_branch, third_branch, fourth_branch], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_st5(x, filter_sizes, reduction_sizes):\n",
    "  first_branch = layers.Conv2D(filter_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "\n",
    "  second_branch_red = layers.Conv2D(reduction_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "\n",
    "  second_branch_1 = layers.Conv2D(int(filter_sizes[1]/2), (3, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(second_branch_red)\n",
    "  \n",
    "  second_branch_2 = layers.Conv2D(int(filter_sizes[1]/2), (1,3), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(second_branch_red)\n",
    "  \n",
    "  third_branch_red = layers.Conv2D(reduction_sizes[1], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(x)\n",
    "  \n",
    "  third_branch = layers.Conv2D(filter_sizes[2], (3, 3), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch_red)\n",
    "  \n",
    "  third_branch_1 = layers.Conv2D(int(filter_sizes[2]/2), (3, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch)\n",
    "  \n",
    "  third_branch_2 = layers.Conv2D(int(filter_sizes[2]/2), (1, 3), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(third_branch)\n",
    "  \n",
    "  fourth_branch = layers.MaxPool2D(pool_size=(3, 3), strides=1, padding=\"SAME\")(x)\n",
    "  \n",
    "  fourth_branch = layers.Conv2D(filter_sizes[3], (1, 1), padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2))(fourth_branch)\n",
    "  \n",
    "  return layers.concatenate([first_branch, second_branch_1, second_branch_2, third_branch_1, third_branch_2, fourth_branch], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the rest of stages\n",
    "\n",
    "def stage_3(x):\n",
    "  filter_sizes = [[64, 128, 32, 32],[128, 192, 96, 64]]\n",
    "  reduction_sizes = [[96, 16],[128, 32]]\n",
    "  for i in range(2):\n",
    "    x = inception_st3(x, filter_sizes[i], reduction_sizes[i])\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_4(x):\n",
    "  filter_sizes = [[192, 208, 48, 64], [160, 224, 64, 64],[128, 256, 64, 64], \n",
    "                  [112, 288, 64, 64], [256, 320, 128, 128]]\n",
    "  reduction_sizes = [[96, 16],[112, 24],[128, 24],[144, 32],[160, 32]]\n",
    "  for i in range(5):\n",
    "    x = inception_st4(x, filter_sizes[i], reduction_sizes[i])\n",
    "    if i == 0:\n",
    "      aux_1 = layers.AveragePooling2D(5, strides=3)(x)\n",
    "      aux_1 = layers.Conv2D(128, (1, 1), padding='SAME', activation='relu')(aux_1)\n",
    "      aux_1 = layers.Flatten()(aux_1)\n",
    "      aux_1 = layers.Dense(1024, activation='relu')(aux_1)\n",
    "      aux_1 = layers.Dropout(0.7)(aux_1)\n",
    "      aux_1 = layers.Dense(1, activation='sigmoid', name='aux_output_1')(aux_1)\n",
    "    elif i == 3:\n",
    "      aux_2 = layers.AveragePooling2D(5, strides=3)(x)\n",
    "      aux_2 = layers.Conv2D(128, (1, 1), padding='SAME', activation='relu')(aux_2)\n",
    "      aux_2 = layers.Flatten()(aux_2)\n",
    "      aux_2 = layers.Dense(1024, activation='relu')(aux_2)\n",
    "      aux_2 = layers.Dropout(0.7)(aux_2)\n",
    "      aux_2 = layers.Dense(1, activation='sigmoid', name='aux_output_2')(aux_2)\n",
    "\n",
    "  return x, aux_1, aux_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_5(x):\n",
    "  filter_sizes = [[256, 320, 128, 128],[384, 384, 128, 128]]\n",
    "  reduction_sizes = [[160, 32],[192,48]]\n",
    "  for i in range(2):\n",
    "    x = inception_st5(x, filter_sizes[i], reduction_sizes[i])\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dummy input, with img dimensions, in order to build the model\n",
    "inp = layers.Input(shape=(96, 96, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  x = stage_1_and_2(inp)\n",
    "  x = stage_3(x)\n",
    "  x = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\")(x)\n",
    "  x, aux_1, aux_2 = stage_4(x)\n",
    "  x = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\")(x)\n",
    "  x = stage_5(x)\n",
    "  x = layers.GlobalAveragePooling2D()(x)\n",
    "  x = layers.Dropout(0.4)(x)\n",
    "  x = layers.Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "  return tf.keras.Model(inp, [x, aux_1, aux_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses, optimizers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the learning rate drop. The code in this cell was taken from here:\n",
    "# https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch. \n",
    "\n",
    "epochs = 100\n",
    "initial_lrate = 0.01\n",
    "\n",
    "def decay(epoch, steps=100):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.96\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "sgd = optimizers.SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
    "\n",
    "\n",
    "lr_sc = callbacks.LearningRateScheduler(decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_backs = [\n",
    "             callbacks.EarlyStopping(monitor='val_main_output_binary_accuracy', patience=3, restore_best_weights=True),\n",
    "             callbacks.TerminateOnNaN(),\n",
    "             lr_sc\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['binary_crossentropy', 'binary_crossentropy', \n",
    "                    'binary_crossentropy'], loss_weights=[1, 0.3, 0.3],\n",
    "                    optimizer=sgd, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, epochs=epochs, validation_data=val, callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

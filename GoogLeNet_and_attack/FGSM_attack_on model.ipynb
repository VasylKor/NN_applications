{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "camelyon = tfds.load('patch_camelyon', as_supervised=True, shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = camelyon['train'].shuffle(1000).batch(32).map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val = camelyon['validation'].batch(32).map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = camelyon['test'].batch(32).map(preprocess).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing inception layers\n",
    "\n",
    "class Inception_st3(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters_version=0):\n",
    "        super(Inception_st3, self).__init__()\n",
    "        self.filter_sizes = [[64, 128, 32, 32],[128, 192, 96, 64]][filters_version]\n",
    "        self.reduction_sizes = [[96, 16],[128, 32]][filters_version]\n",
    "        self.first_fil = layers.Conv2D(self.filter_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                        bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_red = layers.Conv2D(self.reduction_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_fil = layers.Conv2D(self.filter_sizes[1], (3, 3), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_red = layers.Conv2D(self.reduction_sizes[1], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil = layers.Conv2D(self.filter_sizes[2], (3, 3), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil_2 = layers.Conv2D(self.filter_sizes[2], (3, 3), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.MAX = layers.MaxPool2D(pool_size=(3, 3), strides=1, padding=\"SAME\")\n",
    "        self.fourth_fil = layers.Conv2D(self.filter_sizes[3], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "                          \n",
    "              \n",
    "\n",
    "          \n",
    "    def call(self, inputs):\n",
    "\n",
    "                \n",
    "        first_branch = self.first_fil(inputs)\n",
    "  \n",
    "        second_branch_red = self.second_red(inputs)\n",
    "        \n",
    "        second_branch = self.second_fil(second_branch_red)\n",
    "        \n",
    "        third_branch_red = self.third_red(inputs)\n",
    "        \n",
    "        third_branch = self.third_fil(third_branch_red)\n",
    "        \n",
    "        third_branch = self.third_fil_2(third_branch)\n",
    "        \n",
    "        fourth_branch = self.MAX(inputs)\n",
    "        \n",
    "        fourth_branch = self.fourth_fil(fourth_branch)\n",
    "        \n",
    "        return layers.concatenate([first_branch, second_branch, third_branch, fourth_branch], axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_st4(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters_version=0):\n",
    "        super(Inception_st4, self).__init__()\n",
    "        self.filter_sizes = [[192, 208, 48, 64], [160, 224, 64, 64],[128, 256, 64, 64], \n",
    "                            [112, 288, 64, 64], [256, 320, 128, 128]][filters_version]\n",
    "        self.reduction_sizes = [[96, 16],[112, 24],[128, 24],[144, 32],[160, 32]][filters_version]\n",
    "        self.first_fil = layers.Conv2D(self.filter_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                         bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_red = layers.Conv2D(self.reduction_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_fil = layers.Conv2D(self.filter_sizes[1], (1, 7), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_fil_1 = layers.Conv2D(self.filter_sizes[1], (7, 1), padding='SAME', activation='relu',\n",
    "                            kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                            bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_red = layers.Conv2D(self.reduction_sizes[1], (1, 1), padding='SAME', activation='relu',\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                         bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil = layers.Conv2D(self.filter_sizes[2], (1, 7), padding='SAME', activation='relu',\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                         bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil_1 = layers.Conv2D(self.filter_sizes[2], (7, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil_2 = layers.Conv2D(self.filter_sizes[2], (1, 7), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil_3 = layers.Conv2D(self.filter_sizes[2], (7, 1), padding='SAME', activation='relu',\n",
    "                           kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                           bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.MAX = layers.MaxPool2D(pool_size=(3, 3), strides=1, padding=\"SAME\")\n",
    "        self.fourth_fil = layers.Conv2D(self.filter_sizes[3], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "                          \n",
    "              \n",
    "\n",
    "          \n",
    "    def call(self, inputs):\n",
    "\n",
    "                \n",
    "        first_branch = self.first_fil(inputs)\n",
    "  \n",
    "        second_branch_red = self.second_red(inputs)\n",
    "        \n",
    "        second_branch = self.second_fil(second_branch_red)\n",
    "        \n",
    "        second_branch = self.second_fil_1(second_branch)                  \n",
    "        \n",
    "        third_branch_red = self.third_red(inputs)\n",
    "        \n",
    "        third_branch = self.third_fil(third_branch_red)\n",
    "        \n",
    "        third_branch = self.third_fil_1(third_branch)\n",
    "        \n",
    "        third_branch = self.third_fil_2(third_branch)\n",
    "        \n",
    "        third_branch = self.third_fil_3(third_branch)\n",
    "        \n",
    "        fourth_branch = self.MAX(inputs)\n",
    "        \n",
    "        fourth_branch = self.fourth_fil(fourth_branch)\n",
    "        \n",
    "        return layers.concatenate([first_branch, second_branch, third_branch, fourth_branch], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_st5(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters_version=0):\n",
    "        super(Inception_st5, self).__init__()\n",
    "        self.filter_sizes = [[256, 320, 128, 128],[384, 384, 128, 128]][filters_version]\n",
    "        self.reduction_sizes = [[160, 32],[192,48]][filters_version]\n",
    "        self.first_fil = layers.Conv2D(self.filter_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                         bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_red = layers.Conv2D(self.reduction_sizes[0], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_fil = layers.Conv2D(int(self.filter_sizes[1]/2), (3, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.second_fil_1 = layers.Conv2D(int(self.filter_sizes[1]/2), (1,3), padding='SAME', activation='relu',\n",
    "                            kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                            bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_red = layers.Conv2D(self.reduction_sizes[1], (1, 1), padding='SAME', activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                        bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil = layers.Conv2D(self.filter_sizes[2], (3, 3), padding='SAME', activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                        bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil_1 = layers.Conv2D(int(self.filter_sizes[2]/2), (3, 1), padding='SAME', activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                        bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.third_fil_2 = layers.Conv2D(int(self.filter_sizes[2]/2), (1, 3), padding='SAME', activation='relu',\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                        bias_initializer=tf.keras.initializers.Constant(value=0.2))\n",
    "        self.MAX = layers.MaxPool2D(pool_size=(3, 3), strides=1, padding=\"SAME\")\n",
    "        self.fourth_fil = layers.Conv2D(self.filter_sizes[3], (1, 1), padding='SAME', activation='relu',\n",
    "                          kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                          bias_initializer=tf.keras.initializers.Constant(value=0.2)) \n",
    "\n",
    "          \n",
    "    def call(self, inputs):\n",
    "                \n",
    "      first_branch = self.first_fil(inputs)\n",
    "\n",
    "      second_branch_red = self.second_red(inputs)\n",
    "\n",
    "      second_branch_1 = self.second_fil(second_branch_red)\n",
    "      \n",
    "      second_branch_2 = self.second_fil_1(second_branch_red)\n",
    "      \n",
    "      third_branch_red = self.third_red(inputs)\n",
    "      \n",
    "      third_branch = self.third_fil(third_branch_red)\n",
    "      \n",
    "      third_branch_1 = self.third_fil_1(third_branch)\n",
    "      \n",
    "      third_branch_2 = self.third_fil_2(third_branch)\n",
    "      \n",
    "      fourth_branch = self.MAX(inputs)\n",
    "      \n",
    "      fourth_branch = self.fourth_fil(fourth_branch)\n",
    "\n",
    "      return layers.concatenate([first_branch, second_branch_1, second_branch_2, third_branch_1, third_branch_2, fourth_branch], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These components are simply to be put inside a sequential model. Since in GoogLeNet \n",
    "# inception layers of the same stages have different filters sizes for each inner layer, \n",
    "# you can select the appropriate set of sizes by passing an integer from 0 as only \n",
    "# user-dependant argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(x):\n",
    "  labs = []\n",
    "  imgs = []\n",
    "  for images, labels in x:\n",
    "    imgs.append(images)\n",
    "    labs.append(labels)\n",
    "  return tf.convert_to_tensor(np.stack(imgs)), tf.convert_to_tensor(np.array(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to memory limits we will only take a random sample of the original test data\n",
    "\n",
    "tst, tst_y = separate(camelyon['test'].shuffle(500).take(1000).map(preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting single output model\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "              tf.keras.Input(shape=(96, 96, 3)),\n",
    "              layers.Conv2D(64, (7, 7), strides=2, padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2)),\n",
    "              layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\"),\n",
    "              layers.Conv2D(64, (1, 1), strides=1, padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2)),\n",
    "              layers.Conv2D(192, (3, 3), strides=1, padding='SAME', activation='relu',\n",
    "                    kernel_initializer=tf.keras.initializers.glorot_normal,\n",
    "                    bias_initializer=tf.keras.initializers.Constant(value=0.2)),\n",
    "              layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\"),\n",
    "              Inception_st3(0),\n",
    "              Inception_st3(1),\n",
    "              layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\"),\n",
    "              Inception_st4(0),\n",
    "              Inception_st4(1),\n",
    "              Inception_st4(2),\n",
    "              Inception_st4(3),\n",
    "              Inception_st4(4),\n",
    "              layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=\"SAME\"),\n",
    "              Inception_st5(0),\n",
    "              Inception_st5(1),\n",
    "              layers.GlobalAveragePooling2D(),\n",
    "              layers.Dropout(0.4),\n",
    "              layers.Dense(1, activation='sigmoid', name='main_output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the learning rate drop\n",
    "\n",
    "epochs = 100\n",
    "initial_lrate = 0.01\n",
    "\n",
    "def decay(epoch, steps=100):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.96\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "sgd = optimizers.SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
    "\n",
    "\n",
    "lr_sc = callbacks.LearningRateScheduler(decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_backs = [\n",
    "             callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3, restore_best_weights=True),\n",
    "             callbacks.TerminateOnNaN(),\n",
    "             lr_sc\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='binary_crossentropy',\n",
    "                    optimizer=sgd, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(train, epochs=epochs, validation_data=val, callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights just in case\n",
    "\n",
    "#import os\n",
    "\n",
    "# model_1.save_weights(\"model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping model into ART model\n",
    "classifier = TensorFlowV2Classifier(model_1, nb_classes=1, loss_object=loss,\n",
    "                                    input_shape=(96, 96, 3), clip_values=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crafting attack\n",
    "attack = FastGradientMethod(classifier, norm=np.inf, eps=8, eps_step=8, targeted=False,\n",
    "                            num_random_init=0, batch_size=1, minimal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting adversarial images \n",
    "x_adv = attack.generate(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model against all test data\n",
    "model_1.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating one output model against sample from test data \n",
    "model_1.evaluate(tst, tst_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model against adversarial images\n",
    "model_1.evaluate(x_adv, tst_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation proved the attack to be successful even though to a certain extent. \n",
    "# Interestingly, as mentioned, the model without auxiliary outputs \n",
    "# performs no much worse than the whole model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
